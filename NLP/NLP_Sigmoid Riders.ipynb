{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available()) \n",
    "print(torch.cuda.current_device())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:07:37.158660Z",
     "iopub.status.busy": "2021-06-08T05:07:37.158244Z",
     "iopub.status.idle": "2021-06-08T05:07:38.280990Z",
     "shell.execute_reply": "2021-06-08T05:07:38.279821Z",
     "shell.execute_reply.started": "2021-06-08T05:07:37.158576Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3080 Ti Laptop GPU\n",
      "Sat Jan 18 17:57:06 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.36                 Driver Version: 566.36         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   47C    P8             13W /  131W |     862MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     71872      C   ....0_x64__qbz5n2kfra8p0\\python3.8.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    !nvidia-smi\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:09:04.890704Z",
     "iopub.status.busy": "2021-06-08T05:09:04.890284Z",
     "iopub.status.idle": "2021-06-08T05:09:10.706100Z",
     "shell.execute_reply": "2021-06-08T05:09:10.705256Z",
     "shell.execute_reply.started": "2021-06-08T05:09:04.890666Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marwan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarabic.araby as ar\n",
    "\n",
    "import re , emoji, Stemmer, functools, operator, string\n",
    "import torch , optuna, gc, random, os\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
    "from transformers import Trainer , TrainingArguments\n",
    "from transformers.trainer_utils import EvaluationStrategy\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:09:22.601141Z",
     "iopub.status.busy": "2021-06-08T05:09:22.600828Z",
     "iopub.status.idle": "2021-06-08T05:09:22.611993Z",
     "shell.execute_reply": "2021-06-08T05:09:22.610912Z",
     "shell.execute_reply.started": "2021-06-08T05:09:22.601110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "st =  Stemmer.Stemmer('arabic')\n",
    "def data_cleaning (text):\n",
    "  text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "  text = re.sub(r'^http?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "  text = re.sub(r\"http\\S+\", \"\", text)\n",
    "  text = re.sub(r\"https\\S+\", \"\", text)\n",
    "  text = re.sub(r'\\s+', ' ', text)\n",
    "  text = re.sub(\"(\\s\\d+)\",\"\",text) \n",
    "  text = re.sub(r\"$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$\", \"\", text)\n",
    "  text = re.sub(\"\\d+\", \" \", text)\n",
    "  text = ar.strip_tashkeel(text)\n",
    "  text = ar.strip_tatweel(text)\n",
    "  text = text.replace(\"#\", \" \");\n",
    "  text = text.replace(\"@\", \" \");\n",
    "  text = text.replace(\"_\", \" \");\n",
    "  translator = str.maketrans('', '', string.punctuation)\n",
    "  text = text.translate(translator)\n",
    "  em = text\n",
    "  em_split_emoji = emoji.get_emoji_regexp().split(em)\n",
    "  em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
    "  em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
    "  text = \" \".join(em_split)\n",
    "  text = re.sub(r'(.)\\1+', r'\\1', text)\n",
    "  text_stem = \" \".join([st.stemWord(i) for i in text.split()])\n",
    "  text = text +\" \"+ text_stem\n",
    "  text = text.replace(\"آ\", \"ا\")\n",
    "  text = text.replace(\"إ\", \"ا\")\n",
    "  text = text.replace(\"أ\", \"ا\")\n",
    "  text = text.replace(\"ؤ\", \"و\")\n",
    "  text = text.replace(\"ئ\", \"ي\")\n",
    "   \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:09:31.116553Z",
     "iopub.status.busy": "2021-06-08T05:09:31.116192Z",
     "iopub.status.idle": "2021-06-08T05:09:31.636865Z",
     "shell.execute_reply": "2021-06-08T05:09:31.636028Z",
     "shell.execute_reply.started": "2021-06-08T05:09:31.116511Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "OBJ        5233\n",
      "NEG        1317\n",
      "NEUTRAL     654\n",
      "POS         627\n",
      "Name: count, dtype: int64\n",
      "Tweet_ID  Tweet                                                                                                       Label  \n",
      "1         #الرياض #أمطار_الرياض #السعودية #مطر #الرياض_تغرق #أمطار_الرياض #قحاب                                       OBJ        1\n",
      "5232      _:  #التأسيسية \" على وشك الانفجار بعد عودة التهديد بالانسحاب \"                                              OBJ        1\n",
      "5230      بطاقة دعوة #زواج حلوه لـ #الواتس_اب من تصميمنا رتويت ي حبايبي :$                                            POS        1\n",
      "5229      د عبدالمنعم سعيد: إسرائيل تطالب العالم بالاعتراف بفاشيتها وعنصريتها قانون قسم الولاء ليهودية إسرائيل فاشية  NEG        1\n",
      "5228      ماعنديش مشكلة نقبل او نرفض القرض على اسس اقتصادية،لكن انك تلوي الدين عشان تحلل و تحرم هو ده اللي ينرفز      NEG        1\n",
      "                                                                                                                                ..\n",
      "2607      #أبو_الهول #الجيزة #مصر                                                                                     OBJ        1\n",
      "2606      #ولاد_البلد #المنصورة تفريق مسيرة لعناصر \"الإخوان\" في #سمنود بعد الإشتباك مع الأهالي بمنطقة الشحاتية        OBJ        1\n",
      "2605      #بيقولك_أعرف_بلدك الاسكندرية و ده تصويرى ️                                                                  OBJ        1\n",
      "2604      ال ع الشمال ده زييت #باسم_عودة الإرهابي أما اللي على اليمين ده زيت الإستقرار هل عرفتم الفرق ؟               NEUTRAL    1\n",
      "7831      #فولورز_اسلاموفيتش_بيعملوا_لبعض_فولو #فولورز_عفركوش_بيعملو_فولو_لبعض #دخل_كلمة_فسيخ_في_اسم_فيلم #رنا_سماحه  OBJ        1\n",
      "Name: count, Length: 7831, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Use_Train_Extended_Data = False \n",
    "\n",
    "Tweets_Ids_Col_Train =\"Tweet_ID\"\n",
    "Tweets_Text_Col_Train = \"Tweet\"\n",
    "Tweets_Sentiment_Col_Train = \"Label\"\n",
    "Train_Data_File = \"train_data.csv\"\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(Train_Data_File, sep=\",\")\n",
    "\n",
    "print(train_data[Tweets_Sentiment_Col_Train].value_counts())\n",
    "print(train_data.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:09:38.522747Z",
     "iopub.status.busy": "2021-06-08T05:09:38.522420Z",
     "iopub.status.idle": "2021-06-08T05:10:07.785751Z",
     "shell.execute_reply": "2021-06-08T05:10:07.784965Z",
     "shell.execute_reply.started": "2021-06-08T05:09:38.522718Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     الرياض امطار الرياض السعودية مطر الرياض تغرق ا...\n",
       "1     من بين الاسماء محمود القرش، مصر الجديدة واخرين...\n",
       "2     مقتل طفلة لبنانية في تبادل اطلاق نار بين علوين...\n",
       "3        الروح و الجسد مصطفي محمود روح و جسد مصطف محمود\n",
       "4     دعبد المنعم ابو الفتوح فى عيون العالم دعبد منع...\n",
       "5     عندما يستمر القضاء في التحقيق في بلاغات عبثية ...\n",
       "6     جدول اعادة اخر كلام الاثنين يونيو حلقة جمعة ال...\n",
       "7     مرسي بيغير من باسم يوسف عشان باسم الناس بتضحك ...\n",
       "8     اذا استمرت القيادة المصرية الحالية في نهجها فس...\n",
       "9     مش حتقولي ازاي اشجع الكورة لجماهير مش حتقول از...\n",
       "10    سامي الجابر يتحمل كل شيء لانه اعطي الصلاحية كا...\n",
       "11    محمد بديع اطلب من ابي محمد حسني مبارك ان يرفع ...\n",
       "12       بوستر فيلم الشتا االي فات وستر يلم شتا اال فات\n",
       "13    تراجع تصنيف مصر لمركز الاخير عالميا فى مستوى ا...\n",
       "14                                   حزب الكنبة حزب كنب\n",
       "15    استمعت لعمال لا حق في انشاء نقابات مستقلة، ملي...\n",
       "16    وحياة قلبي وافراحه️ الشباب الاهلي حيا قلب افرا...\n",
       "17    مشاهد من مسرح حكم الفرد الجزء الاول مقال اليوم...\n",
       "18    لا اعترف بسفير يدين مواطنه قبل ان يجرى تحقيق م...\n",
       "19    محدث مصر توقع اتفاقات لشراء مليون طن من القمح ...\n",
       "20    دعمرو حمزاوي يشرح المادة الاولي في الدستور الج...\n",
       "21             وجود شي مكملنى الاهلى جود شء مكملني اهلي\n",
       "22    اعرفوهم انقلاب مصر يسقط حكم العسكر الداخلية بل...\n",
       "23    بلاغ ل النايب العام برهامي يدعو لفحشاء والفجور...\n",
       "24    الصحافة العالمية ومحاكمة مرسي لا روبوبليكا الا...\n",
       "25    هانزل علشان مش هاقبل ان ديني يتهان واقف ساكته ...\n",
       "26    الاخت الفاضلة حسين فهمى صاحبة اشهر مواقف سياسي...\n",
       "27    ارجو لكل من يقرا تصريح لى ان يتاكد من مصدره و ...\n",
       "28    عن احساسك كزملكاوى لما عمر جابر جاب الجول انهر...\n",
       "29    الحب هو ان تخالف هواك من اجل مراد حبيبك فالهم ...\n",
       "30    صوتك العالي دليل على ضعف موقفك صوت عال دليل عل...\n",
       "31    رتويت تلقايي لجميع تغريداتك من حسابات حقيقيه ل...\n",
       "32    لو كل زملكاوىه قعدو يشتمو ف ميدو والعيبة انا م...\n",
       "33    يسقط دستور جمهورية مرسي الاخوانية يسقط دستور ج...\n",
       "34    لماذا العرب متاخرين عن الام لانا نعيش حاضرنا ن...\n",
       "35    شاهد سكاي عيد العمال تراجع اعد العاطلين شاهد س...\n",
       "36    محمود عباس الهولوكوست ابشع جريمة في التاريخ ال...\n",
       "37    ان لطاعة نورا في القلب وضياء في الوجه وسعة في ...\n",
       "38    مصر خالد علي السلطة تمارس اجراما سياسيا ضد الف...\n",
       "39    الحلقة العاشرة الجزء الثالث مو عامر ستاند اب ك...\n",
       "40    مثقفون فضحهم الربيع العربي واحد فاضي الام عيد ...\n",
       "41             ناتشوز️ الرياض استيكي ناتشوز️ رياض استيك\n",
       "42    راقب تغريداتگ وماتكتب غرد بصورة غرد بالخير تذك...\n",
       "43    حب سادي زب كبير خليجي عمة ورعان خليجي الرياض ا...\n",
       "44    بنزيما علينا تقديم طيلة المباراة لفوز بها ريال...\n",
       "45    الان هبة موريف منسق منظمة ضيفة اخر كلام على ال...\n",
       "46    نجاوى اليل تجعلكم اقوى كثيرا من اوجاعكم الغاير...\n",
       "47    بيقولك حظروا مقرات ابريل؟ لو يعرفوا الى فيها ه...\n",
       "48    غرد لعين الوصل الوحدة الهلال النصر ريال مدريد ...\n",
       "49    كل ضحكة من شفاتك تقلب الدنيا جنون،انت لدنيا بذ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[Tweets_Text_Col_Train] = train_data[Tweets_Text_Col_Train].apply(lambda x:   data_cleaning(x))\n",
    "\n",
    "# Removing un-needed feilds\n",
    "if Tweets_Ids_Col_Train in train_data.columns:\n",
    "  del train_data[Tweets_Ids_Col_Train]\n",
    "train_data.columns = [Tweets_Text_Col_Train, Tweets_Sentiment_Col_Train]\n",
    "\n",
    "train_data[Tweets_Text_Col_Train].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:10:16.010517Z",
     "iopub.status.busy": "2021-06-08T05:10:16.010160Z",
     "iopub.status.idle": "2021-06-08T05:10:16.777599Z",
     "shell.execute_reply": "2021-06-08T05:10:16.776693Z",
     "shell.execute_reply.started": "2021-06-08T05:10:16.010484Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "Train set: \n",
      "Label\n",
      "OBJ        5230\n",
      "NEG        1317\n",
      "NEUTRAL     653\n",
      "POS         627\n",
      "Name: count, dtype: int64\n",
      "---------------------------\n",
      "Evaluation set: \n",
      "Label\n",
      "OBJ        3\n",
      "NEUTRAL    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Extra_Len = 6 \n",
    "Max_Len = train_data[Tweets_Text_Col_Train].str.split().str.len().max() + Extra_Len\n",
    "print(Max_Len)\n",
    "\n",
    "#Spliting the Training data\n",
    "Test_Size = 0\n",
    "if Use_Train_Extended_Data :\n",
    "  Test_Size = 0.001  \n",
    "                    \n",
    "else :\n",
    "  Test_Size = 0.0005 \n",
    "                    \n",
    "Rand_Seed = 42 \n",
    "\n",
    "train_set, evaluation_set = train_test_split( train_data, test_size= Test_Size, random_state= Rand_Seed)\n",
    "\n",
    "print(\"Train set: \")\n",
    "print(train_set[Tweets_Sentiment_Col_Train].value_counts())\n",
    "print(\"---------------------------\")\n",
    "print (\"Evaluation set: \")\n",
    "print (evaluation_set[Tweets_Sentiment_Col_Train].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:10:23.586396Z",
     "iopub.status.busy": "2021-06-08T05:10:23.586062Z",
     "iopub.status.idle": "2021-06-08T05:10:31.612442Z",
     "shell.execute_reply": "2021-06-08T05:10:31.611647Z",
     "shell.execute_reply.started": "2021-06-08T05:10:23.586363Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     سعوديون يطالبون الجيش المصري باختراع علاج لكور...\n",
       "1     النضافة ،النظام،الراحة و الحرية الي بيحس بيها ...\n",
       "2     عرض الاسبوع الف متابع وش اكثر شي يسهرك صيام ال...\n",
       "3     خمس الاف الامارات الهلال النصر السعودية الكويت...\n",
       "4     حمزاوي لابد من اقالة وزير الداخلية ومدير امن ب...\n",
       "5             غلطت م الاول رنا سماحه غلط م اول رنا سماح\n",
       "6     و انما دغل يعج بالنبت على اختلاف اشكاله والاخت...\n",
       "7     ياباسم عصام سلطان بيسال عليك وبيقول انت فين من...\n",
       "8     لتحميل كتاب تغريد في السعادة و التفاول و الامل...\n",
       "9     غير صحيح وموقفي الرافض سجل في اكثر من مقال بجر...\n",
       "10    يوسف الحسيني لحزب النورخليكم في الدعوة وابعدوا...\n",
       "11    الدكتور كمال الهلباوي يدعم ابوالفتوح دكتور كما...\n",
       "12    الراتب مايكفي الحاجة الاتحاد الهلال النصر الاه...\n",
       "13    فلبيني اسلم قبل يوما في مكتب الدعوة ، وذهب الى...\n",
       "14    تاجيل قضية اعادة اجراءات محاكمة متهما فى مذبحة...\n",
       "15    معلوماتى انك لا تشرب دايات رغم معلوماتي انك لا...\n",
       "16    الدكتورة ايمان جمعة الاستاذة بكلية الاعلام جام...\n",
       "17    جمعية زمزم تكفل بولادة توايم كن سباقا لعلاج ال...\n",
       "18    كل المجد و العرفان لكل الذين قدموا ارواحهم فدا...\n",
       "19    كلمة هيبة محتاجة تشال من القاموس عشان ماحدش يت...\n",
       "20    انه دايما من الرايع ان تكسب الجوايز لان هذا يع...\n",
       "21    اشمعنى انتا تويت يجيلك فولو وانا اتويت يتعملى ...\n",
       "22    يا انصار شفيق الحكمالاجرامي لاخوان لا يعنى ابد...\n",
       "23    الديمقراطية صنعها الغرب لتحكم فى الدول المتخلف...\n",
       "24    صدي الدقهلية جامعة المنصورة عودة المسيرة مرة ا...\n",
       "25    الذين يدافعون عن مرشحهم المفضل بالشتايم يشبهون...\n",
       "26    عبد المنعم ابو الفتوح اعداء المصريون فى الخارج...\n",
       "27    ال ع الشمال ده زيت باسم عودة الارهابي اما الي ...\n",
       "28    لو فتحوا باب الهجرة مش هيفضل في مصر و لا واحد ...\n",
       "29    من قرى مصر تخلو من الصرف الصحي وتحتاج ل مليار ...\n",
       "30    ليفربول انهزم والاهلي الحين ما يطمن والاخلاق ز...\n",
       "31    انا رفضت وقف فيلم السبكي ورافضه لالغاء مشهد رف...\n",
       "32    و من اروع ما كتب بلال فضل امشوا يرحمكم اله و م...\n",
       "33               رضاك يارب كلمتين وبس رضا يارب كلمت وبس\n",
       "34    من ساند مبارك وكان فاسدا او ايد مرسي ومان ارها...\n",
       "35                لما انت تسيبها الاول لما انت تسيب اول\n",
       "36    البوابة نيوز شيرين نادمة على عدايها ل هيفاء وه...\n",
       "37    د علاء الاسواني ما الذي تميز به الاعلام المصري...\n",
       "38    اين سيقضي مرسي يوم دعلاء الاسواني يكتب مقاله ب...\n",
       "39    السابق هو نص رسالة تلقيتها بشان حملة اعلامية ل...\n",
       "40    الانتخابات البرلمانية القادمة دعمرو حمزاوي يتش...\n",
       "41    ذلكم بانه اذا دعي اله وحده كفرتم وان يشرك به ت...\n",
       "42    اوعى تنسى عمليات الماءالابيض على يد نخبةمن الا...\n",
       "43    الاخوان يشعلون النيران بنقطة مرور الطالبية ب ا...\n",
       "44    لما يبقى الي بينقلوا الاخبار لناس بالعقلية دي ...\n",
       "45    لا حول ولا قوة الا باله سبحان اله العظيم وبحمد...\n",
       "46    كلام ام الشهيد محمد مصطفى بيجيب من الاخر مرسي ...\n",
       "47    عيد العمال احتفلوا بعيد العمال ايها البطالة يق...\n",
       "48    البطل لا يهزم عندما يخسر، بل يهزم عندما ياس وي...\n",
       "49    فيليكس عندما صعد لفضاء الخارجي استغرق ساعات وه...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Tweets_Ids_Col_Test = \"Tweet_ID\"\n",
    "Tweets_Text_Col_Test = \"Tweet\"\n",
    "Test_Data_File = \"test_data.csv\"\n",
    "\n",
    "test_data = pd.read_csv(Test_Data_File, sep=\",\")\n",
    "test_data.columns = [Tweets_Ids_Col_Test,Tweets_Text_Col_Test]\n",
    "\n",
    "test_data[Tweets_Text_Col_Test] = test_data[Tweets_Text_Col_Test].apply(lambda x:   data_cleaning(x))\n",
    "test_data[Tweets_Text_Col_Test].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:10:42.690399Z",
     "iopub.status.busy": "2021-06-08T05:10:42.690058Z",
     "iopub.status.idle": "2021-06-08T05:10:42.703450Z",
     "shell.execute_reply": "2021-06-08T05:10:42.702177Z",
     "shell.execute_reply.started": "2021-06-08T05:10:42.690365Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Model_Used = \"UBC-NLP/MARBERT\"\n",
    "\n",
    "#Model_Used = \"xlm-roberta-large\"\n",
    "\n",
    "#Model_Used = \"asafaya/bert-base-arabic\"  # Example\n",
    "#Model_Used = \"aubmindlab/bert-base-arabertv2\"  # Example\n",
    "\n",
    "Task_Name = \"classification\"\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        train,\n",
    "        test,\n",
    "        label_list,\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.label_list = label_list\n",
    "        \n",
    "class BERTModelDataset(Dataset):\n",
    "    def __init__(self, text, target, model_name, max_len, label_map):\n",
    "      super(BERTModelDataset).__init__()\n",
    "      self.text = text\n",
    "      self.target = target\n",
    "      self.tokenizer_name = model_name\n",
    "      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "      self.max_len = max_len\n",
    "      self.label_map = label_map\n",
    "  \n",
    "    def __len__(self):\n",
    "      return len(self.text)\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "      text = str(self.text[item])\n",
    "      text = \" \".join(text.split())\n",
    "    \n",
    "      encoded_review = self.tokenizer.encode_plus(\n",
    "      text,\n",
    "      max_length= self.max_len,\n",
    "      add_special_tokens= True,\n",
    "      return_token_type_ids=False,\n",
    "      pad_to_max_length=True,\n",
    "      truncation='longest_first',\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt'\n",
    "    )\n",
    "      input_ids = encoded_review['input_ids'].to(device)\n",
    "      attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "      return InputFeatures(input_ids=input_ids.flatten(), attention_mask=attention_mask.flatten(), label=self.label_map[self.target[item]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:10:49.365078Z",
     "iopub.status.busy": "2021-06-08T05:10:49.364437Z",
     "iopub.status.idle": "2021-06-08T05:10:49.379863Z",
     "shell.execute_reply": "2021-06-08T05:10:49.378903Z",
     "shell.execute_reply.started": "2021-06-08T05:10:49.365031Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def model_init():\n",
    "  return AutoModelForSequenceClassification.from_pretrained(Model_Used, return_dict=True, num_labels=len(label_map))\n",
    "\n",
    "def compute_metrics(p): #p should be of type EvalPrediction\n",
    "  preds = np.argmax(p.predictions, axis=1)\n",
    "  assert len(preds) == len(p.label_ids)\n",
    "  print(classification_report(p.label_ids,preds))\n",
    "  #print(confusion_matrix(p.label_ids,preds))\n",
    "\n",
    "  macro_f1_pos_neg = f1_score(p.label_ids,preds,average='macro',labels=[1,2])\n",
    "  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
    "  macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
    "  macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
    "  acc = accuracy_score(p.label_ids,preds)\n",
    "  return {\n",
    "      'macro_f1' : macro_f1,\n",
    "      'macro_f1_pos_neg' : macro_f1_pos_neg,  \n",
    "      'macro_precision': macro_precision,\n",
    "      'macro_recall': macro_recall,\n",
    "      'accuracy': acc\n",
    "  }\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:10:53.779202Z",
     "iopub.status.busy": "2021-06-08T05:10:53.778885Z",
     "iopub.status.idle": "2021-06-08T05:10:55.483298Z",
     "shell.execute_reply": "2021-06-08T05:10:55.482441Z",
     "shell.execute_reply.started": "2021-06-08T05:10:53.779171Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJ', 'NEG', 'POS', 'NEUTRAL']\n",
      "Label\n",
      "OBJ        5230\n",
      "NEG        1317\n",
      "NEUTRAL     653\n",
      "POS         627\n",
      "Name: count, dtype: int64\n",
      "{'OBJ': 0, 'NEG': 1, 'POS': 2, 'NEUTRAL': 3}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "label_list = list(train_set[Tweets_Sentiment_Col_Train].unique())\n",
    "\n",
    "print(label_list)\n",
    "print(train_set[Tweets_Sentiment_Col_Train].value_counts())\n",
    "\n",
    "data_set = Dataset( \"KAUST\", train_set, evaluation_set, label_list )\n",
    "\n",
    "label_map = { v:index for index, v in enumerate(label_list) }\n",
    "print(label_map)\n",
    "\n",
    "train_dataset = BERTModelDataset(train_set[Tweets_Text_Col_Train].to_list(),\n",
    "                                 train_set[Tweets_Sentiment_Col_Train].to_list(),Model_Used,Max_Len,label_map)\n",
    "\n",
    "evaluation_dataset = BERTModelDataset(evaluation_set[Tweets_Text_Col_Train].to_list(),\n",
    "                                      evaluation_set[Tweets_Sentiment_Col_Train].to_list(),Model_Used,Max_Len,label_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:16:10.793089Z",
     "iopub.status.busy": "2021-06-08T05:16:10.792767Z",
     "iopub.status.idle": "2021-06-08T05:16:10.801836Z",
     "shell.execute_reply": "2021-06-08T05:16:10.801057Z",
     "shell.execute_reply.started": "2021-06-08T05:16:10.793059Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#define training arguments\n",
    "training_args = TrainingArguments(\"./train\")\n",
    "#training_args.lr_scheduler_type = 'cosine'\n",
    "training_args.lr_scheduler_type = 'linear'\n",
    "training_args.evaluate_during_training = True\n",
    "training_args.adam_epsilon =1e-8 \n",
    "\n",
    "training_args.learning_rate = 1.8e-5 # use this with org data  \n",
    "training_args.fp16 = True\n",
    "#training_args.per_device_train_batch_size = 16 #64 \n",
    "#training_args.per_device_eval_batch_size = 16 # 64 \n",
    "training_args.per_device_train_batch_size = 32 \n",
    "training_args.per_device_eval_batch_size =  32\n",
    "training_args.gradient_accumulation_steps = 2\n",
    "training_args.num_train_epochs= 10\n",
    "#training_args.warmup_steps = 0 \n",
    "training_args.warmup_steps = int(0.1 * (len(train_dataset) // training_args.per_device_train_batch_size) * training_args.num_train_epochs)\n",
    "training_args.max_grad_norm = 1.0\n",
    "\n",
    "#training_args.evaluation_strategy = EvaluationStrategy.EPOCH\n",
    "training_args.evaluation_strategy = \"steps\"\n",
    "training_args.eval_steps = 100  \n",
    "training_args.logging_steps = 200\n",
    "training_args.save_strategy = \"steps\"\n",
    "training_args.save_steps = 500\n",
    "training_args.early_stopping_patience = 3  # Stop if no improvement after 3 evaluations\n",
    "training_args.load_best_model_at_end = True\n",
    "#training_args.save_steps = 100000 \n",
    "training_args.seed = 42 \n",
    "training_args.disable_tqdm = False\n",
    "training_args.optim = \"adafactor\"\n",
    "training_args.weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:16:15.269285Z",
     "iopub.status.busy": "2021-06-08T05:16:15.268972Z",
     "iopub.status.idle": "2021-06-08T05:16:48.645626Z",
     "shell.execute_reply": "2021-06-08T05:16:48.644576Z",
     "shell.execute_reply.started": "2021-06-08T05:16:15.269255Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marwan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\transformers\\modeling_utils.py:1038: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marwan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\transformers\\trainer.py:363: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = ShardedGradScaler() if self.sharded_dpp else torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "training_args.dataloader_pin_memory = False\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "set_seed(Rand_Seed) \n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model_init(),\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset= evaluation_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:16:55.580612Z",
     "iopub.status.busy": "2021-06-08T05:16:55.580238Z",
     "iopub.status.idle": "2021-06-08T05:57:28.112257Z",
     "shell.execute_reply": "2021-06-08T05:57:28.111314Z",
     "shell.execute_reply.started": "2021-06-08T05:16:55.580575Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "1e-05\n",
      "1e-08\n",
      "244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1220 [00:00<?, ?it/s]C:\\Users\\marwan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\transformers\\tokenization_utils_base.py:2137: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "C:\\Users\\marwan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\transformers\\trainer.py:1247: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      " 16%|█▋        | 200/1220 [00:42<03:37,  4.69it/s]\n",
      " 16%|█▋        | 200/1220 [00:42<03:37,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9485, 'learning_rate': 8.19672131147541e-06, 'epoch': 1.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 400/1220 [01:25<02:51,  4.79it/s]\n",
      " 33%|███▎      | 401/1220 [01:25<02:56,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6262, 'learning_rate': 8.401639344262295e-06, 'epoch': 3.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 600/1220 [02:09<02:11,  4.71it/s]\n",
      " 49%|████▉     | 601/1220 [02:09<02:13,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4229, 'learning_rate': 6.352459016393443e-06, 'epoch': 4.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 800/1220 [02:52<01:32,  4.54it/s]\n",
      " 66%|██████▌   | 800/1220 [02:52<01:32,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2656, 'learning_rate': 4.30327868852459e-06, 'epoch': 6.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1000/1220 [03:44<00:48,  4.56it/s]\n",
      " 82%|████████▏ | 1000/1220 [03:44<00:48,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.203, 'learning_rate': 2.254098360655738e-06, 'epoch': 8.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1200/1220 [04:50<00:06,  3.10it/s]\n",
      " 98%|█████████▊| 1200/1220 [04:50<00:06,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1583, 'learning_rate': 2.0491803278688524e-07, 'epoch': 9.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1220/1220 [04:56<00:00,  3.23it/s]\n",
      "100%|██████████| 1220/1220 [04:56<00:00,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 296.9246, 'train_samples_per_second': 4.109, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1220, training_loss=0.4324196907340503, metrics={'train_runtime': 296.9246, 'train_samples_per_second': 4.109, 'epoch': 10.0})"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Max_Len)\n",
    "print(training_args.learning_rate)\n",
    "print(training_args.adam_epsilon)\n",
    "print(training_args.warmup_steps)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T05:59:01.112259Z",
     "iopub.status.busy": "2021-06-08T05:59:01.111942Z",
     "iopub.status.idle": "2021-06-08T06:03:40.959965Z",
     "shell.execute_reply": "2021-06-08T06:03:40.959145Z",
     "shell.execute_reply.started": "2021-06-08T05:59:01.112229Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marwan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\transformers\\tokenization_utils_base.py:2137: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def predict(text, tokenizer):\n",
    " \n",
    "  encoded_review = tokenizer.encode_plus(\n",
    "    text,\n",
    "    max_length=Max_Len,\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    pad_to_max_length=True, #True,\n",
    "    truncation='longest_first',\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'\n",
    "  )\n",
    "\n",
    "  input_ids = encoded_review['input_ids'].to(device) \n",
    "  attention_mask = encoded_review['attention_mask'].to(device)\n",
    "    \n",
    "\n",
    "  output = trainer.model(input_ids, attention_mask)\n",
    "  _, prediction = torch.max(output[0], dim=1)\n",
    "  return prediction[0]\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(Model_Used)\n",
    "\n",
    "prediction_list = []\n",
    "i = 0\n",
    "for tweet in test_data[Tweets_Text_Col_Test]:\n",
    "    id = test_data[Tweets_Ids_Col_Test][i]\n",
    "  \n",
    "    pre = predict(tweet, tokenizer)\n",
    "    pre_txt = label_list[pre]\n",
    "   \n",
    "    if pre_txt == 'POS':\n",
    "        prediction_list.append('POS')  # Positive sentiment\n",
    "    elif pre_txt == 'NEG':\n",
    "        prediction_list.append('NEG')  # Negative sentiment\n",
    "    elif pre_txt == 'OBJ':\n",
    "        prediction_list.append('OBJ')  # Objective or factual content\n",
    "    elif pre_txt == 'NEUTRAL':\n",
    "        prediction_list.append('NEUTRAL')  # Neutral sentiment or ambiguous context\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T06:04:01.279866Z",
     "iopub.status.busy": "2021-06-08T06:04:01.279557Z",
     "iopub.status.idle": "2021-06-08T06:04:01.488260Z",
     "shell.execute_reply": "2021-06-08T06:04:01.487406Z",
     "shell.execute_reply.started": "2021-06-08T06:04:01.279836Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\\n",
      "     Tweet_ID    Label\n",
      "0        1000  NEUTRAL\n",
      "1        1001  NEUTRAL\n",
      "2        1002      OBJ\n",
      "3        1003      OBJ\n",
      "4        1004      OBJ\n",
      "...       ...      ...\n",
      "1995     2995      OBJ\n",
      "1996     2996      OBJ\n",
      "1997     2997      NEG\n",
      "1998     2998      OBJ\n",
      "1999     2999      OBJ\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "File saved successfully to C:\\Users\\marwan\\Desktop\\nlp\\sub_test12.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "directory_path = r'C:\\Users\\marwan\\Desktop\\nlp'\n",
    "\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "\n",
    "result_file = os.path.join(directory_path, 'sub_test12.csv')\n",
    "\n",
    "results = pd.DataFrame({'Tweet_ID': test_data[Tweets_Ids_Col_Test].astype(str), 'Label': prediction_list},\n",
    "                       columns=['Tweet_ID', 'Label'])\n",
    "print(results)\n",
    "\n",
    "results.to_csv(result_file, sep=\",\", index=False)\n",
    "\n",
    "print(f\"File saved successfully to {result_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
